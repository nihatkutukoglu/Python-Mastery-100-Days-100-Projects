# -*- coding: utf-8 -*-
"""Day21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zKrhhNTUMPQ98-uPJOy_0hLGML5LpQ1U
"""

# ---- DAY 21 PROJECT : WEB SCRAPING(WIKIPEDIA) ----
import requests
from bs4 import BeautifulSoup

# url_ornek = "https://en.wikipedia.org/wiki/Python_(programming_language)"
# cevap_ornek = requests.get(url_ornek)

# if cevap_ornek.status_code == 200:
#     print("İlk 500 karakter:")
#     print(cevap_ornek.text[:500])
# else:
#     print(f"Veri alınamadı. Durum kodu: {cevap_ornek.status_code}")

# print("-" * 70)

# html_icerik_ornek = "<h1>Ana Başlık</h1><p>Bu örnek bir paragraftır</p><a href='https://example.com'>Buraya Tıkla</a>"
# soup_ornek = BeautifulSoup(html_icerik_ornek, "html.parser")

# print("BeautifulSoup örnek çıktıları:")
# print(f"h1 etiketi metni: {soup_ornek.h1.text}")
# print(f"p etiketi metni: {soup_ornek.p.text}")

print("-" * 30)

def wikipedia_sayfasini_al(konu):

  url = f"https://tr.wikipedia.org/wiki/{konu.replace(' ', '_')}"
  cevap = requests.get(url)

  if cevap.status_code == 200:
    return cevap.text
  else:
    print(f"Veri alınamadı. Durum kodu: {cevap.status_code}. Konuyu kontrol edin ve tekrar deneyin.")
    return None

def makale_basligini_al(soup):
  return soup.find('h1').text

def makale_ozetini_al(soup):
  paragraflar = soup.find_all('p')
  for para in paragraflar:
    if para.text.strip():
      return para.text.strip()
  return "Özet bulunamadı"

def basliklari_al(soup):
  basliklar = [baslik.text.strip() for baslik in soup.find_all(['h2', 'h3', 'h4'])]
  return basliklar

def ilgili_baglantilari_al(soup):
  baglantilar = []
  for a_etiketi in soup.find_all('a', href=True):
    href = a_etiketi['href']
    # Türkçe Wikipedia bağlantıları için de aynı mantığı koruyoruz.
    if href.startswith('/wiki/') and ":" not in href:
      baglantilar.append(f"https://tr.wikipedia.org{href}")
  return list(set(baglantilar))[:10]

def ana():
  konu = input("Wikipedia'da aramak istediğiniz bir konu (  a_b kullanarak ) girin: ").strip()
  sayfa_icerigi = wikipedia_sayfasini_al(konu)

  if sayfa_icerigi:
    soup = BeautifulSoup(sayfa_icerigi, 'html.parser')
    baslik = makale_basligini_al(soup)
    ozet = makale_ozetini_al(soup)
    basliklar = basliklari_al(soup)
    ilgili_baglantilar = ilgili_baglantilari_al(soup)

    print("\n--- Wikipedia Makale Detayları ---")
    print(f"\nBaşlık: {baslik}")
    print(f"\nÖzet: {ozet}")
    print("\nBaşlıklar:")
    for baslik_txt in basliklar[:5]:
      print(f"- {baslik_txt}")

    print("\nİlgili Bağlantılar:")
    for baglanti in ilgili_baglantilar:
      print(f"- {baglanti}")

if __name__ == "__main__":
  ana()












